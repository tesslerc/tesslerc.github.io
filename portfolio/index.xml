<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Publications on Chen Tessler</title>
    <link>https://tesslerc.github.io/portfolio/</link>
    <description>Recent content in Publications on Chen Tessler</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 27 Nov 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://tesslerc.github.io/portfolio/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Distributional Policy Optimization: An Alternative Approach for Continuous Control - NeurIPS 2019</title>
      <link>https://tesslerc.github.io/portfolio/dpo/</link>
      <pubDate>Wed, 27 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tesslerc.github.io/portfolio/dpo/</guid>
      <description>We propose a method for learning distributional policies, policies which are not limited to parametric distribution functions (e.g., Gaussian and Delta). This approach overcomes sub-optimal local extremum in continuous control regimes.</description>
    </item>
    
    <item>
      <title>Action Robust Reinforcement Learning and Applications in Continuous Control - ICML 2019</title>
      <link>https://tesslerc.github.io/portfolio/action_robust/</link>
      <pubDate>Tue, 27 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tesslerc.github.io/portfolio/action_robust/</guid>
      <description>Action Robust is a special case of robustness, in which the agent is robust to uncertainty in the performed action. We show (theoretically) that this form of robustness has efficient solutions and (empirically) results in policies which are robust to common uncertainties in robotic domains.</description>
    </item>
    
    <item>
      <title>Reward Constrained Policy Optimization - ICLR 2019</title>
      <link>https://tesslerc.github.io/portfolio/rcpo/</link>
      <pubDate>Thu, 27 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tesslerc.github.io/portfolio/rcpo/</guid>
      <description>Learning a policy which adheres to behavioral constraints is an important task. Our algorithm, RCPO, enables the satisfaction of not only discounted constraints but also average and probabilistic, in an efficient manner.</description>
    </item>
    
    <item>
      <title>A Deep Hierarchical Approach to Lifelong Learning in Minecraft - AAAI 2017</title>
      <link>https://tesslerc.github.io/portfolio/hdrln/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tesslerc.github.io/portfolio/hdrln/</guid>
      <description>We propose a lifelong learning system that has the ability to reuse and transfer knowledge from one task to another while efficiently retaining the previously learned knowledge-base. Knowledge is transferred by learning reusable skills to solve tasks in Minecraft, a popular video game which is an unsolved and high-dimensional lifelong learning problem.</description>
    </item>
    
  </channel>
</rss>