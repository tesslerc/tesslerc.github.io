<!DOCTYPE html>
<html lang="en">
    
    


    <head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta http-equiv="Cache-Control" content="public" />
<!-- Enable responsiveness on mobile devices -->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="generator" content="Hugo 0.73.0" />

    
    
    

<title>About me â€¢ Chen Tessler</title>


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="About me"/>
<meta name="twitter:description" content="I&rsquo;m currently pursuing my P.hD in Reinforcement Learning at the Technion Institute of Technology, Israel, under the supervision of Prof. Shie Mannor.
Reinforcement Learning (RL) is a learning paradigm that highly resembles how we, as humans, learn. The agent, i.e., the learning algorithm, learns through interaction with the environment. By observing the current state of the system, it decides what action to take, after which the environment transitions to a new state and produces the agent with a reward."/>

<meta property="og:title" content="About me" />
<meta property="og:description" content="I&rsquo;m currently pursuing my P.hD in Reinforcement Learning at the Technion Institute of Technology, Israel, under the supervision of Prof. Shie Mannor.
Reinforcement Learning (RL) is a learning paradigm that highly resembles how we, as humans, learn. The agent, i.e., the learning algorithm, learns through interaction with the environment. By observing the current state of the system, it decides what action to take, after which the environment transitions to a new state and produces the agent with a reward." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://tesslerc.github.io/about/" />
<meta property="article:published_time" content="2014-04-02T00:00:00+00:00" />
<meta property="article:modified_time" content="2014-04-02T00:00:00+00:00" /><meta property="og:site_name" content="Chen Tessler" />


    


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">








<link rel="stylesheet" href="/scss/hyde-hyde.919cd87a8432a9d1f4fcc089bd2b05ae8c035af181b310c7ff59f805fcee805f.css" integrity="sha256-kZzYeoQyqdH0/MCJvSsFrowDWvGBsxDH/1n4BfzugF8=">


<link rel="stylesheet" href="/scss/print.2744dcbf8a0b2e74f8a50e4b34e5f441be7cf93cc7de27029121c6a09f9e77bc.css" integrity="sha256-J0Tcv4oLLnT4pQ5LNOX0Qb58&#43;TzH3icCkSHGoJ&#43;ed7w=" media="print">



    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
    <link rel="shortcut icon" href="/favicon.png">
    
    

    <script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>
</head>


    <body class=" ">
    
<div class="sidebar">
  <div class="container ">
    <div class="sidebar-about">
      <span class="site__title">
        <a href="https://tesslerc.github.io/">Chen Tessler</a>
      </span>
      
        
        
        
        <div class="author-image">
          <img src="https://tesslerc.github.io/img/chen_tessler.jpg" alt="Author Image" class="img--circle img--headshot element--center">
        </div>
        
      
      
      <p class="site__description">
        
      </p>
    </div>
    <div class="collapsible-menu">
      <input type="checkbox" id="menuToggle">
      <label for="menuToggle">Chen Tessler</label>
      <div class="menu-content">
        <div>
	<ul class="sidebar-nav">
		 
		 
			 
				<li>
					<a href="/about/">
						<span>About</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/posts/">
						<span>Posts</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/portfolio/">
						<span>Research</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/cv/">
						<span>Curriculum Vitae</span>
					</a>
				</li>
			 
		
	</ul>
</div>

        <section class="social">
	
	<a href="https://twitter.com/tesslerc" rel="me"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a>
	
	
	
	<a href="https://github.com/tesslerc" rel="me"><i class="fab fa-github fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
	
	<a href="https://linkedin.com/in/chentessler" rel="me"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
	
	
	<a href="mailto:chen.tessler@gmail.com" rel="me"><i class="fas fa-at fa-lg" aria-hidden="true"></i></a>
	
</section>

      </div>
    </div>
    
<div class="copyright">
  &copy; 2020 htr3n
  
    <a href="https://creativecommons.org/licenses/by-sa/4.0">CC BY-SA 4.0</a>
  
</div>



  </div>
</div>

        <div class="content container">
            
    
<article>
  <header>
    <h1>About me</h1>
    

  </header>
  
  
  <div class="post">
    <p>I&rsquo;m currently pursuing my P.hD in Reinforcement Learning at the Technion Institute of Technology, Israel, under the supervision of <a href="https://shie.net.technion.ac.il/">Prof. Shie Mannor</a>.</p>
<p>Reinforcement Learning (RL) is a learning paradigm that highly resembles how we, as humans, learn. The agent, i.e., the learning algorithm, learns through interaction with the environment. By observing the current state of the system, it decides what action to take, after which the environment transitions to a new state and produces the agent with a reward. The goal of the agent is to maximize the accumulative reward.</p>
<p>In my research I focus on deep reinforcement learning (DRL), where we use deep learning techniques (neural networks) to solve reinforcement learning problems.</p>
<p>Specifically, I am interested in finding the problems that are unique to DRL (e.g., which occur due to non-linear function approximation) and how they can be solved or mitigated in order to improve empirical performance.</p>

  </div>
  
</article>


        </div>
        
    

<script defer src="https://use.fontawesome.com/releases/v5.5.0/js/all.js" integrity="sha384-GqVMZRt5Gn7tB9D9q7ONtcp4gtHIUEW/yG7h98J7IpE3kpi+srfFyyB/04OV6pG0" crossorigin="anonymous"></script>




    



    </body>
</html>
